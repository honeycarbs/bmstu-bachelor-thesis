\chapter{Исследовательский раздел}

\section{Предварительная обработка обучающего набора данных}
Перед составлением тренировочной и обучающих выборок корпус DUSHA был проанализирован на предмет процентного соотношения каждой классов в разметке. Распределение классов разметки по доменам представлено в таблице \ref{tab:stats}.

\begin{table}[H]
	\centering
	\caption{Распределение классов разметки в корпусе DUSHA}\label{tab:stats}
	\begin{tabular}{|c|R|E|R|E|}
		\hline
		\textit{Домен} & \multicolumn{2}{c|}{\textit{Crowd}} & \multicolumn{2}{c|}{\textit{Podcast}} \\ \hline
		\textit{Эмоция} & \textit{Количество, шт.} & \textit{Доля, \%} & \textit{Количество, шт.} & \textit{Доля, \%} \\ \hline
		positive & 15446 & 9.40 & 5909 & 6.53 \\ \hline
		sad & 23316 & 14.18 & 1170 & 1.29 \\ \hline
		angry & 17120 & 10.41 & 2057 & 2.27 \\ \hline
		neutral & 106850 & 65.00 & 81104 & 89.66 \\ \hline
		other & 1655 & 1.01\% & 222 & 0.25 \\ \hline
	\end{tabular}
\end{table}
Из таблицы \ref{tab:stats} видно, что  классы в разметке неравномерно распределены. Поэтому для обучения и проверки скрытой марковской модели был использован не весь набор данных DUSHA, а его часть. Из файлов разметки были извлечены все аудиофайлы, длина которых не превышала 3 секунды и разметка которых не содержала значения <<other>>. В обучающую выборку было включено 1000 аудиофайлов каждого класса разметки. Объем данных обучающей выборки, которая подается на вход классификатору, представлен в таблице \ref{tab:stats-my}.

\begin{table}[htbp]
	\centering
	\caption{Объем данных обучающей выборки}\label{tab:stats-my}
	\renewcommand{\arraystretch}{1.3}
	\begin{tabular}{|c|F|F|F|}
		\hline
		\textit{Подгруппа} & \textit{Всего} & \textit{Тренировочная выборка} & \textit{Тестовая выборка} \\ \hline
		angry & 41 мин. 43 сек. & 33 мин. 21 сек. & 08 мин. 21 сек. \\ \hline
		neutral & 41 мин. 52 сек. & 33 мин. 37 сек. & 08 мин. 15 сек. \\ \hline
		positive & 41 мин. 56 сек. & 33 мин. 37 сек. & 08 мин. 19 сек. \\ \hline
		sad & 43 мин. 18 сек. & 34 мин. 39 сек. & 08 мин. 38 сек. \\ \hline
	\end{tabular}
\end{table}

\section{Результат классификации и его оценка}
Результат распознавания на тренировочной выборке представлен в виде таблицы \ref{tab:confusion-matrix}. 
\begin{table}[H]
	\centering
	\caption{Матрица ошибок}\label{tab:confusion-matrix}
	\renewcommand{\arraystretch}{1.3}
	\begin{tabular}{|E|E|E|E|E|}
		\hline
		\textit{Экспертная} & \multicolumn{4}{c|}{\textit{Оценка классификатора}} \\ \cline{2-5}
		\textit{оценка} & \textit{angry} & \textit{neutral} & \textit{positive} & \textit{sad} \\ \hline
		\textit{angry} & 0.29662 & 0.26158 & 0.32541 & 0.1164 \\ \hline
		\textit{neutral} & 0.16625 & 0.55375 & 0.1075 & 0.1725 \\ \hline
		\textit{positive} & 0.27875 & 0.295 & 0.29375 & 0.1325 \\ \hline
		\textit{sad} & 0.26625 & 0.4525 & 0.1075 & 0.17375 \\ \hline
	\end{tabular}
\end{table}
Для оценки производительности классификатора на основе матрицы ошибок можно учесть несколько показателей оценки, таких как точность (\textit{англ. precision}), полнота (\textit{англ. recall}) и F1-мера.

Точность системы в пределах класса -- это доля элементов действительно принадлежащих данному классу относительно всех элементов которые система отнесла к этому классу. Рассчитывается согласно \ref{eq:precision}:
\begin{equation}\label{eq:precision}
	\mathrm{Persition_c} = \cfrac{A_{c,\,c}}{\displaystyle\sum_{i = 1}^{n}A_{c,\,i}},
\end{equation}
где $A$ -- матрица ошибок, $c$ -- индекс класса для которого вычисляется точность в матрице ошибок. Значение точности для каждого класса разметки представлено в таблице \ref{tab:pres}.

\begin{table}[H]
	\centering
	\caption{Значение точности для каждого класса разметки}\label{tab:pres}
	\begin{tabular}{|E|Q|Q|Q|Q|Q|}
		\hline
		\textit{Эмоция} &  angry & neutral & positive & sad & $\sum$ \\
		\hline
		$\mathrm{Persition_c}$ &  & & & & \\
		\hline
	\end{tabular}
\end{table}
Полнота системы -- это доля найденных классфикатором элементов принадлежащих классу относительно всех элементов этого класса в тестовой выборке. Рассчитывается согласно \ref{eq:recall}:
\begin{equation}\label{eq:recall}
	\mathrm{Recall_c} = \cfrac{A_{c,\,c}}{\displaystyle\sum_{i = 1}^{n}A_{i,\,c}},
\end{equation}
де $A$ -- матрица ошибок, $c$ -- индекс класса для которого вычисляется полнота в матрице ошибок. Значение полноты для каждого класса разметки представлено в таблице \ref{tab:recall}.

\begin{table}[H]
	\centering
	\caption{Значение точности для каждого класса разметки}\label{tab:recall}
	\begin{tabular}{|E|Q|Q|Q|Q|Q|}
		\hline
		\textit{Эмоция} &  angry & neutral & positive & sad & $\sum$ \\
		\hline
		$\mathrm{Recall_c}$ &  & & & & \\
		\hline
	\end{tabular}
\end{table}
F-мера представляет собой гармоническое среднее между точностью и полнотой и вычисляется согласно  \ref{eq:f1}:
\begin{equation}\label{eq:f1}
	\mathrm{F} = 2 \cdot \cfrac{\mathrm{Precision} \cdot \mathrm{Recall}}{\mathrm{Precision} + \mathrm{Recall}}
\end{equation}
%Соответственно, для класса <<angry>> точность равна примерно 0.294, для класса <<neutral>> -- 0.354, для класса <<positive>> -- 0.352 и для класса <<sad>> -- 0.292. Результирующая точность классификатора рассчитывается как арифметическое среднее его точности по всем классам. Результирующая точность данного классификатора составляет примерно 28 \%.
%
%Полнота системы -- это доля найденных классфикатором элементов принадлежащих классу относительно всех элементов этого класса в тестовой выборке. Рассчитывается согласно \ref{eq:recall}:
%\begin{equation}\label{eq:recall}
%	\mathrm{Recall} = \cfrac{A_{c,\,c}}{\displaystyle\sum_{i = 1}^{n}A_{i,\,c}},
%\end{equation}
%где $A$ -- матрица ошибок, $c$ -- индекс класса для которого вычисляется полнота в матрице ошибок. Соответственно, для класса <<angry>> полнота равна примерно 0.297, для класса <<neutral>> -- 0.554, для класса <<positive>> -- 0.294 и для класса <<sad>> -- 0.174. Результирующая полнота классификатора рассчитывается аналогично результирующей точности. Результирующая полнота данного классификатора составляет примерно 33\%.
%
%F-мера представляет собой гармоническое среднее между точностью и полнотой и вычисляется согласно  \ref{eq:f1}:
%\begin{equation}\label{eq:f1}
%	\mathrm{F} = 2 \cdot \cfrac{\mathrm{Precision} \cdot \mathrm{Recall}}{\mathrm{Precision} + \mathrm{Recall}} \approx 0.326.
%\end{equation}
%Оценочная $\mathrm{F}-$средняя мера классификатора примерно равна 33\%.

\section{Зависимость качества классификации от объема обучающей выборки}

\section{Зависимость качества классификации от качества кластеризации}


\section*{Вывод}\addcontentsline{toc}{section}{Вывод}