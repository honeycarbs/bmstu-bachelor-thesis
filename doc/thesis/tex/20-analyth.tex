\chapter{Аналитический раздел}
\section{Категоризация эмоциональных данных}
Одной из главных проблем в исследованиях, связанных с определением эмоционального состояния диктора по голосу, является отсутствие четкого определения эмоции. Подход к классификации эмоций влияет на процесс аннотирования. Сегодня широко используются три подхода к категоризации эмоциональных данных: дискретный, многомерный и гибридный.
\subsection{Дискретное пространство эмоций}
Дискретный подход основан на выделении фундаментальных (базовых) эмоций, сочетания которых порождают разнообразие эмоциональных явлений. Разные авторы называют разное число таких эмоций -- от двух до десяти. П.~Экман на основе изучения лицевой экспрессии выделяет пять базовых эмоций: гнев, страх, отвращение, печаль и радость. Первоначальная версия 1999 года также включала <<удивление>> \cite{Ekman1972, Ekman1992}. Р.~Плутчик \cite{Plutchik1980} выделяет восемь базисных эмоций, деля их на четыре пары, каждая из которых связана с определенным действием: страх, уныние, удивление и т.~д. 

На сегодняшний день существование базовых эмоций ставится под сомнение. Теория встречает ряд концептуальных проблем, таких как, например, эмпирическое определение набора базовых эмоций или критерии синхронизации эмоциональных реакций. Однако, многие решения в области автоматического детектирования эмоций основаны на дискретной модели эмоциональной сферы. Например, решение компании <<Affectiva>>.~\cite{Affectica}

\subsection{Многомерное пространство эмоций}
Многомерное пространство представляет собой эмоции в координатном многомерном пространстве. В качестве ее источника рассматривают идею В. Вундта о том, что многогранность чувств
человека можно описать с помощью трех измерений: удовольствие-неудовольствие, расслабление-напряжение, возбуждение-успокоение. Вундт заключил, \cite{Вундт1984} что эти измерения охватывают все разнообразие эмоциональных состояний. Данные для этой теории были получены с помощью метода интроспекции.

Эмоциональная сфера представляется как многомерное пространство, образованное некоторым
количеством осей координат. Оси задаются полюсами первичных характеристик эмоций. Отдельные эмоции -- это точки, местоположение которых в <<эмоциональном>> пространстве определяется степенью выраженности этих параметров.

Один из примеров описываемого подхода -- модель Дж.~Рассела. В ней водится двумерный базис, в котором каждая эмоция характеризуется валентностью (\textit{англ. valence}) и интенсивностью (\textit{англ. arousal}). Измерение валентности отражает то,
насколько хорошо человек ощущает себя на уровне субъективного переживания от максимального неудовольствия до максимального удовольствия. Измерение активации связано с
субъективным чувством энергии и ранжируется в диапазоне от дремоты до бурного возбуждения. Такой подход используется, например, в наборе данных <<RECOLA>> \cite{RECOLA}.

Аналогично вопросу о количестве эмоций в дискретной модели, вопрос о количестве измерений остается открытым. Использование только двух критикуется на том основании, что они не позволяют устанавливать различия между отдельными эмоциональными состояниями (например, страх, гнев, ревность, презрение и др. имеют отрицательную валентность и высокую активацию).

\subsection{Гибридное пространство эмоций}
Гибридная модель представляет собой комбинацию дискретной и многомерной модели. Примером такой модели являются <<Песочные часы эмоций>>, предложенные Камбрией, Ливингстоном и Хуссейном.~\cite{hourglass} 

Согласно этой классификации, в отдельной области $n$-мерного эмоционального пространства различия между эмоциями могут определяться в терминах измерений, имеющих отношение к этой области. Эмоции могут быть сопоставимы по измерениям внутри и вне категорий, и каждая категория может иметь свои отличительные признаки.~\cite{Russell2003} Каждое измерение характеризуется шестью уровнями силы, с которой выражены эмоции. Данные уровни обозначаются набором из двадцати четырех эмоций. Поэтому совершенно любая эмоция может рассматриваться как и фиксированное состояние, так и часть пространства, связанная с другими эмоциями нелинейными отношениями. 

\section{Представление адудиосигнала}
\begin{center}
	\color{red}речеобразование, представление сигнала, дискретизация
\end{center}
Результатом дискретизации является набор измерений $s(n)$, который был получен в момент времени $\Delta t \cdot n$ значений непрерывного сигнала.

Задача распознавания эмоций решается непосредственно по оцифрованному сигналу. Выделяется два этапа решения задачи:
\begin{itemize}
	\item выделение и отбор информативных признаков;
	\item классификация (сопоставление признаков).
\end{itemize}
\section{Выделение информативных признаков}
Важной особенностью речевого сигнала является его условная стационарность на небольших промежутках (от 20 до 40 мс).~\cite{frames} По этой причине для оцифровки сигнал разделяется на фреймы. Деление происходит таким образом, чтобы каждая точка перекрывалась дважды.~\cite{mfcc-steps}

Однако, даже при работе с фреймами, сигнал содержит много избыточной для анализа информации. Поэтому для того, чтобы привести сигнал в вид, который будет использован алгоритмом распознавания, требуется выделить набор информативных признаков речевого сигнала. К выделяемому набору признаков предъявляются следующие требования: \cite{features-must}
\begin{itemize}
	\item с помощью выделенного набора признаков можно получить наиболее значимую информацию из акустического сигнала;
	\item размер выборки должен быть минимальным для увеличения быстродействия разрабатываемой системы распознавания эмоций.
\end{itemize}
Информативные признаки эмоциональной речи можно разбить на две категории: спектральные (линейные спектральные частоты, кепстральные коэффициенты линейной шкалы частот, кепстральные коэффициенты мел-шкалы частот) и лингвистические (мелодика речи, интенсивность, ритм, тембр, сила голоса).~\cite{schuller2011recognising} Системы голосового детектирования эмоционального состояния, работающие со спонтанной речью, могут комбинировать акустические и лингвистические информативные признаки. 

%В практике автоматического распознавания речи наиболее распространенными алгоритмами извлечения информативных признаков являются мел-кепстральные коэффициенты и кодирование с линейным прогнозированием.
%\subsection{Спектральные признаки}
\subsection{Мел-кепстральные коэффициенты}
Для представления огибающей спектра, которой описывается форма голосового тракта были введены мел-кепстральные коэффициенты (\textit{англ. MFCC}).~\cite{mfcc}

Шкала Мел (рисунок \ref{fig:mel-hz}) соотносит воспринимаемую частоту или высоту чистого тона (мел) с фактической измеренной частотой (Гц). Люди гораздо лучше различают небольшие изменения высоты звука на низких частотах, чем на высоких.~\cite{mel} 
\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			legend pos = north west,
			xmin=0, xmax=10000,
			ymin=0, ymax=3200,
			/pgf/number format/.cd,
			use comma,
			1000 sep={},
			xlabel= Фактическая измеренная частота (Гц),
			ylabel= Высота чистого тона (мел) ,
			grid = both,
			grid style = {dashed, lightgray!35},
			xtick distance = 500,
			ytick distance = 200,
			width = 0.98\textwidth,
			tick label style={font=\scriptsize},
			scaled ticks=false,
			height=0.3\textheight,]
			\addplot[
			red,
			semithick,
			domain=-0:10000,
			] {1127.01048 * ln(1 + x /700)};
		\end{axis}
	\end{tikzpicture}
	\caption{График зависимости частоты от мел}
	\label{fig:mel-hz}
\end{figure}

Вычисление мел-кепстральных коэффициентов заключается в следующем. Для каждого фрейма $x_j(n)$ выполняется дискретное преобразование Фурье (\ref{eq:dpf}):
\begin{equation}\label{eq:dpf}
	X_j(k) = \displaystyle\sum_{n = 0}^{N-1} x_j(n)w(n)\exp{-\cfrac{2\pi i}{N}kn},\;0 \leq k < N,
\end{equation}
где $j$ -- номер фрейма, $w(n)$ -- оконная функция Хэмминга, используемая для уменьшения утечки ДПФ на интервале конечной длительности. 

Следующим шагом вычисляется банк мел-фильтров из $M$ треугольных фильтров. Для этого треугольные фильтры умножаются на периодограмму и суммируются. Каждый треугольный фильтр моделируются с помощью функции \ref{eq:mel-filter}:
\begin{equation}\label{eq:mel-filter}
	H_m(k) = \begin{cases}
				0, & k < f(m - 1), \\
				\cfrac{k - f(m - 1)}{f(m) - f(m - 1)}, & f(m - 1) \leq k < f(m),\\
				\cfrac{f(m + 1) - k}{f(m + 1) - f(m)}, & f(m) \leq k < f(m + 1),\\
				0, & k > f(m + 1).\\
			\end{cases}
\end{equation}
Далее производится расчет логарифмического значения энергии компонент спектра на выходе каждого фильтра~(\ref{eq:mel-tmp}):
\begin{equation}\label{eq:mel-tmp}
	T_j(m) = \ln \sum_{k = 0}^{N - 1}P_j(k)H_m(k),\;0 \leq m < M.
\end{equation}
Поскольку ДПФ характеристик синтезированных фильтров \ref{eq:mel-filter} взаимно пересекаются, а энергии на выходе фильтров существенно коррелируют, для вычисления MFCC необходимо использовать дискретное косинусное преобразование (\ref{eq:mel-final}), чтобы устранить возникающие корреляци:
\begin{equation}\label{eq:mel-final}
	c_j(m) = \sum_{m=0}^{M-1}T_j(m)\cos\left(\cfrac{\pi n\left(m + \cfrac{1}{2}\right)}{M}\right),\;0 \leq n < M.
\end{equation}
После получения $c_j(m)$, коэффициент $c_j(0)$ отбрасывается, так как он не несет информации о речи диктора
и задает постоянное смещение.~\cite{frames}
\subsection{Кепстральные коэффициенты линейного предсказания}
%Коэффициенты линейного предсказания (\textit{англ. LPC}) используются для оценки периода основного тона, формант и других информативных признаков эмоциональной речи. 
Кепстральные коэффициенты используются для оценки периода основного тона, формант и других информативных признаков эмоциональной речи. 

Кепстр может быть получен путем линейного предсказания (\textit{англ. LP}). Смысл анализа на основе линейного предсказания заключается в том, что участок речевого сигнала $n$ можно аппроксимировать линейной комбинацией $p$ предыдущих участков сигнала согласно \ref{eq:lpc}: \cite{lpc-general}
\begin{equation}\label{eq:lpc}
	s(n) \approx a_{1}s(n - 1) + a_{2}s(n - 2) + a_{3}s(n - 3) + \dots + a_{p}s(n - p),
\end{equation}
где $\{a_i\}^{p}_{i=1}$ -- коэффициенты линейного предсказания, считаются постоянными на протяжении времени фрейма. Эти коэффициенты используются для аппроксимации участка речевого сигнала. Разница между предсказанным и действительным участком сигнала называется погрешностью предсказания и вычисляется согласно \ref{eq:lpc-error}
\begin{equation}\label{eq:lpc-error}
	e(n) = s(n) - \hat{s}(n) = s(n) - \sum_{k = 1}^{p}a_ks(n - k),
\end{equation}
откуда видно, что погрешность предсказания представляет собой сигнал на выходе системы с передаточной функцией (\ref{eq:lpc-a}):
\begin{equation}\label{eq:lpc-a}
	A(z) = 1 - \sum_{k = 1}^{p}a_kz.
\end{equation}


Коэффициенты $\{a_i\}^{p}_{i=1}$ можно получить, минимизируя кратковременную энергию погрешности предсказания, вычисляемую согласно \ref{eq:lpc-energy}:
\begin{equation}\label{eq:lpc-energy}
	E_n = \sum_{m}\left[s_n(m) - \sum_{k = 1}^{p}a_ks_n(m - k)\right],
\end{equation}
где $s_n(m)$ -- сегмент речевого сигнала, выбранный в окрестности фрейма $n$. Минимизировать $E_n$ следует путем вычисления $\cfrac{\delta E_n}{\delta a_i} = 0,\;i = 1, 2, \dots, p$. После нахождения $a_ks$, кепстральные коэффициенты вычисляются с помощью \ref{eq:lpc-cepstr}:
\begin{equation}\label{eq:lpc-cepstr}
	\begin{aligned}
		C_0 = \log_ep,\\
		C_m = a_m + \sum_{m - 1}^{k = 1}\cfrac{k}{m}C_ka_{m - k} && \text{при}\; 1 < m < p, \\
		C_m = \sum_{m - 1}^{k = m - p}\cfrac{k}{m}C_ka_{m - k} && \text{при}\; m > p. \\
	\end{aligned}
\end{equation}



\section{Существующие наборы речевых данных}
\subsection{}
\section{Классификаторы, используемые в SER}
\section{Постановка задачи}